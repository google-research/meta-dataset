import meta_dataset.data.config

# Default values for sampling variable shots / ways.
EpisodeDescriptionConfig.min_ways = 5
EpisodeDescriptionConfig.max_ways_upper_bound = 50
EpisodeDescriptionConfig.max_num_query = 10
EpisodeDescriptionConfig.max_support_set_size = 500
EpisodeDescriptionConfig.max_support_size_contrib_per_class = 100
EpisodeDescriptionConfig.min_log_weight = -0.69314718055994529  # np.log(0.5)
EpisodeDescriptionConfig.max_log_weight = 0.69314718055994529  # np.log(2)
EpisodeDescriptionConfig.ignore_dag_ontology = False

# It is possible to override some of the above defaults only for meta-training.
# An example is shown in the following two commented-out lines.
# train/EpisodeDescriptionConfig.min_ways = 5
# train/EpisodeDescriptionConfig.max_ways_upper_bound = 50

# Other default values for the data pipeline.
DataConfig.image_height = 84
DataConfig.shuffle_buffer_size = 1000
DataConfig.read_buffer_size_bytes = 1048576  # 1 MB (1024**2)
DataConfig.num_prefetch = 64

# Default parameters for support set data augmentation
process_episode.support_data_augmentation = @SupportSetDataAugmentation()
SupportSetDataAugmentation.enable_jitter = True
SupportSetDataAugmentation.jitter_amount = 0
SupportSetDataAugmentation.enable_gaussian_noise = True
SupportSetDataAugmentation.gaussian_noise_std = 0.0

# Default parameters for query set data augmentation
process_episode.query_data_augmentation = @QuerySetDataAugmentation()
QuerySetDataAugmentation.enable_jitter = False
QuerySetDataAugmentation.jitter_amount = 0
QuerySetDataAugmentation.enable_gaussian_noise = False
QuerySetDataAugmentation.gaussian_noise_std = 0.0

# Default parameters for batch data augmentation
process_batch.batch_data_augmentation = @BatchDataAugmentation()
BatchDataAugmentation.enable_jitter = True
BatchDataAugmentation.jitter_amount = 0
BatchDataAugmentation.enable_gaussian_noise = True
BatchDataAugmentation.gaussian_noise_std = 0.0

